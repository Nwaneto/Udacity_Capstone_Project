{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
    "\n",
    "Next we used an indepandent train.py file to first get the data extracted from https://gist.githubusercontent.com/Nwaneto/0d1477bd10c92f8b16ab19306d21a17f/raw/0af3078c0d174e26039ab31525487ceaceda77b0/parkinson-classification-data.csv , then define the parameters (C , max_iter), then clean the data (by removing the name of the personne and defining the dependent and independent variable) and finally set the training and the testing data\n",
    "\n",
    "Train.py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core.run import Run\n",
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "def clean_data(data):\n",
    "\n",
    "# Clean the data x_df = data.to_pandas_dataframe().dropna() x_df.drop(\"name\", inplace=True, axis=1) y_df = x_df.pop(\"status\")\n",
    "\n",
    "return x_df, y_df\n",
    "\n",
    "def main(): # Add arguments to the script parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--C', type=float, default=1.0, help=\"Inverse of regularization strength. Smaller values cause stronger regularization\") parser.add_argument('--max_iter', type=int, default=100, help=\"Maximum number of iterations to converge\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory # Data is located at:\n",
    "\n",
    "path_file=\"https://gist.githubusercontent.com/Nwaneto/0d1477bd10c92f8b16ab19306d21a17f/raw/0af3078c0d174e26039ab31525487ceaceda77b0/parkinson-classification-data.csv\"\n",
    "\n",
    "`ds =TabularDatasetFactory.from_delimited_files(path=path_file)`\n",
    "\n",
    "x, y = clean_data(ds)\n",
    "\n",
    "`# Split data into train and test sets.`\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "run.log(\"Regularization Strength:\", np.float(args.C)) run.log(\"Max iterations:\", np.int(args.max_iter))\n",
    "\n",
    "model = LogisticRegression(C=args.C, max_iter=args.max_iter).fit(x_train, y_train)\n",
    "\n",
    "accuracy = model.score(x_test, y_test) run.log(\"Accuracy\", np.float(accuracy))\n",
    "\n",
    "if __name__ == '__main__': main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-137760\n",
      "Azure region: southcentralus\n",
      "Subscription id: 61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\n",
      "Resource group: aml-quickstarts-137760\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'Parkinson-classification-HDrive'\n",
    "\n",
    "experiment=Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
    "\n",
    "The algorithm we choose for this classification problem, is LogisticRegression because we are trying to predict if a patient will have the parkinson disease based on a range of biomedical voice measurements (yes or no) which means two outcomes.\n",
    "\n",
    "And To improve the model we optimize the hyperparameters using Azure Machine Learning's tuning capabilities Hyperdrive\n",
    "\n",
    "First of all, we define the hyperparameter space to sweep over. which means tuning the C and max_iter parameters. In this step, we use the random sampling RandomParameterSampling to try different configuration sets of hyperparameters to maximize the primary metric to make the tuning more specific\n",
    "\n",
    "Then we define the termination Policy for every run using BanditPolicy based on a slack factor equal to 0.01 as criteria for evaluation to conserves resources by terminating runs that are poorly performing and anssure that every run will give better result than the one before\n",
    "\n",
    "Once completed we create the SKLearn estimator\n",
    "\n",
    "An finally we define the hyperdrive configuration where we set 20 as the maximum of iteration (why because we don't have a lot of data) and used the element defined above before submiting the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded....................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Wait timeout has been reached\n",
      "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
     ]
    }
   ],
   "source": [
    "amlcompute_cluster_name = \"cpu-clusters\"\n",
    "\n",
    "try:\n",
    "    aml_compute = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2',\n",
    "                                                           max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "aml_compute.wait_for_completion(show_output=True , min_node_count = 1, timeout_in_minutes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n"
     ]
    }
   ],
   "source": [
    "#Create the different params that  will be using during training\n",
    "param_sampling =RandomParameterSampling( {\n",
    "    \"--C\":  choice(0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "    \"--max_iter\":  choice(100, 150, 200, 250, 300)\n",
    "    }\n",
    ")\n",
    "\n",
    "#Create an early termination policy.\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=1, slack_factor=0.01)\n",
    "\n",
    "#Create the estimator and the hyperdrive\n",
    "estimator =  SKLearn(source_directory='./', \n",
    "                entry_script='train.py', compute_target=aml_compute)\n",
    "\n",
    "\n",
    "hyperdrive_run_config =HyperDriveConfig(hyperparameter_sampling=param_sampling, \n",
    "                                    primary_metric_name='Accuracy', \n",
    "                                    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                    policy=early_termination_policy,\n",
    "                                    max_total_runs=20,\n",
    "                                    max_concurrent_runs=4,\n",
    "                                    estimator=estimator\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Submit the experiment\n",
    "\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()\n",
    "\n",
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])\n",
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Save and register the best model\n",
    "model = best_run.register_model(model_name='Parkinson_detection', model_path='./')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
